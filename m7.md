ohhh yes—great next moves. Let’s make **M7: Performance + Example App**. I’ll give you a crisp plan and drop-in code you can paste in. You can let Codex wire it up.

# M7 scope (two tracks)

1. **Stress & performance**

- Bulk inserts (10k–100k docs), large+deep JSON, array-heavy queries (`json_each`).
- Complex filters + ordering + pagination.
- Concurrent writers (WAL on) including **SafeModel** version conflicts.
- “Plan quality” checks with `EXPLAIN`/`EXPLAIN QUERY PLAN`.
- Optional micro-benchmarks with `pytest-benchmark`.

2. **Example app (FastAPI)**

- Minimal but realistic: `User` ↔ `Address` (ref), `Order` (list-of-refs).
- CRUD + list with filtering (`min_age`, `city`, `q` substring), ordering & limit.
- Uses **SQLerModel** (sync) for simplicity; later mirror async if you want.
- Ships as an example in `examples/fastapi/` and runs in CI “examples” job.

---

## 1) Stress tests (drop-in)

### Dev dep (once)

Add `pytest-benchmark` as a dev dep (if you want measured timings):

```bash
uv add --dev pytest-benchmark
```

### tests/perf/test_bulk_insert.py

```python
# tests/perf/test_bulk_insert.py
import json
import random
import string
import pytest
from sqler import SQLerDB
from sqler.query import SQLerField as F, SQLerQuery

def _rand_str(n=16):
    return "".join(random.choice(string.ascii_letters) for _ in range(n))

def _doc(i, depth=3, width=4):
    """Generate a moderately heavy nested document."""
    d = {"i": i, "name": _rand_str(12), "tags": [random.randint(0, 9) for _ in range(8)]}
    cur = d
    for lvl in range(depth):
        cur["level"] = lvl
        cur["child"] = {"w": {f"k{j}": j*i for j in range(width)}}
        cur = cur["child"]
    return d

@pytest.fixture(scope="function")
def perf_db():
    db = SQLerDB.in_memory(shared=False)  # on-disk also fine; in-mem is fastest
    db._ensure_table("perf")
    yield db
    db.close()

def test_bulk_insert_50k(perf_db, benchmark):
    docs = [_doc(i) for i in range(50_000)]
    def _run():
        perf_db.bulk_upsert("perf", docs)
    benchmark(_run)

def test_heavy_filter_sort_limit(perf_db, benchmark):
    # seed
    perf_db.bulk_upsert("perf", [_doc(i) for i in range(20_000)])
    # helpful index
    perf_db.create_index("perf", "i")
    # query
    f_i = F("i")
    q = SQLerQuery("perf", perf_db.adapter).filter((f_i >= 10_000) & (f_i < 11_000)).order_by("i").limit(200)
    def _run():
        return q.all()  # json strings
    result = benchmark(_run)
    # sanity
    assert len(result) == 200
```

### tests/perf/test_json_each_queries.py

```python
# tests/perf/test_json_each_queries.py
import json
import random
import pytest
from sqler import SQLerDB
from sqler.query import SQLerField as F, SQLerQuery

@pytest.fixture(scope="function")
def array_db():
    db = SQLerDB.in_memory(shared=False)
    db._ensure_table("arrs")
    # seed: tags as array of ints + nested “events”
    for i in range(15_000):
        db.insert_document("arrs", {
            "name": f"row{i}",
            "tags": [random.randint(0, 100) for _ in range(12)],
            "events": [{"type": "a", "val": i%7}, {"type": "b", "val": (i*3)%11}],
        })
    yield db
    db.close()

def test_contains_vs_isin(array_db, benchmark):
    tags = F("tags")
    q = SQLerQuery("arrs", array_db.adapter).filter(tags.contains(42))
    def _run():
        return len(q.all())
    n1 = benchmark(_run)
    # isin with two numbers
    q2 = SQLerQuery("arrs", array_db.adapter).filter(tags.isin([17, 42]))
    def _run2():
        return len(q2.all())
    n2 = benchmark(_run2)
    # sanity: both return some rows
    assert n1 > 0 and n2 > 0

def test_nested_any(array_db, benchmark):
    # any on array-of-objects: events[].val > 8
    expr = F(["events"]).any()["val"] > 8
    q = SQLerQuery("arrs", array_db.adapter).filter(expr)
    def _run():
        return len(q.all())
    n = benchmark(_run)
    assert n > 0
```

### tests/perf/test_concurrent_writes.py

```python
# tests/perf/test_concurrent_writes.py
import threading
import time
import random
import pytest
from sqler import SQLerDB
from sqler.models.safe import SQLerSafeModel, StaleVersionError

class Counter(SQLerSafeModel):
    name: str
    count: int

def _worker(increment_times, errors, done_evt):
    for _ in range(increment_times):
        # optimistic retry loop
        for _try in range(10):
            obj = Counter.query().filter(Counter.ref("self").field("name") == "global").first()
            if obj is None:
                continue
            v = obj.count
            obj.count = v + 1
            try:
                obj.save()
                break
            except StaleVersionError:
                time.sleep(0.001)
                continue
        else:
            errors.append("max_retries")
    done_evt.set()

def test_concurrent_increments(tmp_path):
    db = SQLerDB.on_disk(tmp_path / "wal.db")
    # ensure WAL (already defaulted in adapter factory, but be explicit)
    db.adapter.execute("PRAGMA journal_mode=WAL;")
    db.adapter.commit()

    Counter.set_db(db)
    Counter(name="global", count=0).save()

    threads = []
    errors: list[str] = []
    done = []

    N_THREADS = 8
    INCR = 500

    for _ in range(N_THREADS):
        e = threading.Event()
        t = threading.Thread(target=_worker, args=(INCR, errors, e))
        t.start()
        threads.append(t)
        done.append(e)

    for t in threads:
        t.join()

    # check final value
    obj = Counter.query().filter(Counter.ref("self").field("name") == "global").first()
    assert obj.count == N_THREADS * INCR
    assert not errors
    db.close()
```

> Notes
> • The `Counter.ref("self")` trick assumes the model-aware field treats the current table; if you didn’t wire that alias, just fetch by query on `"name"` via a normal F("name") comparison and `SQLerQuery` instead of the model helper.
> • For truly high loads, run this on-disk with WAL and maybe `uv run pytest -k concurrent -q`.

---

## 2) FastAPI example app

**Structure:**

```
examples/fastapi/
  app.py
  models.py
  db.py
```

### examples/fastapi/models.py

```python
from pydantic import BaseModel
from sqler.models import SQLerModel
from sqler.models.ref import as_ref
from typing import Optional, List

class Address(SQLerModel):
    city: str
    country: str

class Order(SQLerModel):
    total: float
    note: str

class User(SQLerModel):
    name: str
    age: int
    # reference to Address and list of references to Orders
    address: Optional[dict] = None
    orders: List[dict] = []

    def set_address(self, addr: Address):
        if addr._id is None:
            raise ValueError("Save address first")
        self.address = as_ref(addr)

    def add_order(self, order: Order):
        if order._id is None:
            raise ValueError("Save order first")
        self.orders.append(as_ref(order))
```

### examples/fastapi/db.py

```python
from sqler import SQLerDB
from .models import User, Address, Order

_db = None

def init_db(path: str | None = None):
    global _db
    _db = SQLerDB.on_disk(path) if path else SQLerDB.in_memory(shared=False)
    User.set_db(_db)
    Address.set_db(_db)
    Order.set_db(_db)
    # helpful indices
    User.ensure_index("age")
    User.ensure_index("address._id")
    Address.ensure_index("city")
    Order.ensure_index("total")
    return _db

def get_db():
    return _db

def close_db():
    global _db
    if _db:
        _db.close()
        _db = None
```

### examples/fastapi/app.py

```python
from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from .db import init_db, close_db
from .models import User, Address, Order
from sqler.query import SQLerField as F

app = FastAPI(title="SQLer Demo")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_methods=["*"], allow_headers=["*"]
)

@app.on_event("startup")
def on_start():
    init_db()  # in-memory; change to on-disk by passing a path

@app.on_event("shutdown")
def on_stop():
    close_db()

# ---- Address CRUD ----
@app.post("/addresses")
def create_address(city: str, country: str):
    a = Address(city=city, country=country).save()
    return a.model_dump() | {"_id": a._id}

# ---- User CRUD ----
@app.post("/users")
def create_user(name: str, age: int, address_id: int | None = None):
    u = User(name=name, age=age)
    if address_id is not None:
        addr = Address.from_id(address_id)
        if addr is None:
            raise HTTPException(404, "address not found")
        u.set_address(addr)
    u.save()
    return u.model_dump() | {"_id": u._id}

@app.get("/users/{user_id}")
def get_user(user_id: int):
    u = User.from_id(user_id)
    if u is None:
        raise HTTPException(404)
    return u.model_dump() | {"_id": u._id}

@app.get("/users")
def list_users(
    min_age: int | None = Query(None),
    city: str | None = Query(None),
    q: str | None = Query(None),
    limit: int = Query(50, ge=1, le=500),
):
    qs = User.query()
    if min_age is not None:
        qs = qs.filter(F("age") >= min_age)
    if city:
        # relationship-aware filter
        qs = qs.filter(User.ref("address").field("city") == city)
    if q:
        qs = qs.filter(F("name").like(f"%{q}%"))
    # order by age asc, limit
    qs = qs.order_by("age").limit(limit)
    # resolve relationships (default True); users come back hydrated
    users = qs.all()
    return [u.model_dump() | {"_id": u._id} for u in users]

@app.post("/orders")
def create_order(total: float, note: str = ""):
    o = Order(total=total, note=note).save()
    return o.model_dump() | {"_id": o._id}

@app.post("/users/{user_id}/orders/{order_id}")
def attach_order(user_id: int, order_id: int):
    u = User.from_id(user_id)
    o = Order.from_id(order_id)
    if not u or not o:
        raise HTTPException(404)
    u.add_order(o)
    u.save()
    return {"ok": True}
```

Run locally:

```bash
uv run uvicorn examples.fastapi.app:app --reload
```

Then hit:

- `POST /addresses?city=Kyoto&country=JP`
- `POST /users?name=Alice&age=30&address_id=<id>`
- `GET /users?min_age=25&city=Kyoto&q=li&limit=10`

> If you want the **async** version later, we can mirror this app using `AsyncSQLerDB` and `AsyncSQLerModel`, `async def` endpoints, and `await` calls. The route signatures remain the same.

---

## CI: add perf smoke & example app smoke (optional)

- Keep perf tests behind marker so CI can skip heavy ones by default.
- Example app smoke can just import the app and run one TestClient call.

Example perf marker:

```python
# conftest.py (repo root or tests/perf/)
def pytest_addoption(parser):
    parser.addoption("--perf", action="store_true", help="run performance tests")

def pytest_collection_modifyitems(config, items):
    if config.getoption("--perf"):
        return
    skip_perf = pytest.mark.skip(reason="add --perf to run")
    for item in items:
        if "perf" in item.nodeid:
            item.add_marker(skip_perf)
```

CI job tweak (examples step already exists): leave perf off in CI, run locally:

```bash
uv run pytest tests/perf -q --benchmark-only --perf
```

---

## That’s M7 ✅

If you give Codex this message, it has everything to implement:

- three perf test files (plus optional marker),
- and the FastAPI example (3 files) with instructions.

When those are green, we can choose M8. My vote: **mid-chain scoped `any().where(...)`** (turn that xfail into a pass) + **micro-bench harness** that compares `LIKE` vs proper `json_each` membership across sizes, and a tiny profiling doc with query plan tips.
